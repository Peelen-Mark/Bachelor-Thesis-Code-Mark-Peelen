{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from scipy.linalg import svd\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "mirna_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\mirna.csv')\n",
    "gene_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\gene.csv')\n",
    "methy_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\methyl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        cg00000292\n",
       "1        cg00002426\n",
       "2        cg00003994\n",
       "3        cg00005847\n",
       "4        cg00007981\n",
       "            ...    \n",
       "22528    cg27657249\n",
       "22529    cg27661264\n",
       "22530    cg27662379\n",
       "22531    cg27662877\n",
       "22532    cg27665659\n",
       "Name: Unnamed: 0, Length: 22533, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the first column of each dataset (the feature names)\n",
    "mirna_data.pop(mirna_data.columns[0])\n",
    "gene_data.pop(gene_data.columns[0])\n",
    "methy_data.pop(methy_data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(values):\n",
    "    # Scale Z-score\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(values.T)\n",
    "\n",
    "    # Power Transformation\n",
    "    transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "    data_transformed = transformer.fit_transform(scaled_data)\n",
    "    \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datasets):\n",
    "    data = []\n",
    "    dataset_names = ['miRNA', 'gene expression', 'methylation']\n",
    "   \n",
    "    for x in datasets:\n",
    "        # Preprocess the data\n",
    "        X = x.to_numpy()\n",
    "        \n",
    "        # Calculate the percentage of zeros in each row\n",
    "        zero_percentage = np.mean(X == 0, axis=1)\n",
    "\n",
    "        # Get the indices of the rows with less than 20% zeros\n",
    "        keep_indices = np.where(zero_percentage < 0.2)[0]\n",
    "\n",
    "        # Remove the rows with 20% or more zeros\n",
    "        X_without_zeros = X[keep_indices, :]\n",
    "        \n",
    "        # Change 0 values to NaN for the KNN imputer\n",
    "        X_without_zeros[X_without_zeros == 0] = np.nan\n",
    "        \n",
    "        # Determine the amount of neighbours\n",
    "        N = round(np.sqrt(x.shape[1]))\n",
    "        \n",
    "        # Start KNN imputer\n",
    "        imputer = KNNImputer(n_neighbors=N+2)\n",
    "        X = imputer.fit_transform(X_without_zeros)\n",
    " \n",
    "        # Scale the data without the missing values\n",
    "        dataset = scaling(X)\n",
    "        \n",
    "        # Perform Bayesian Gaussian Mixture model with the diagonal covariance matrix\n",
    "        bgmm_model = BayesianGaussianMixture(n_components = dataset.shape[0], covariance_type='diag')\n",
    "        bgmm_model.fit(dataset)\n",
    "        \n",
    "        # Get covariances\n",
    "        covariances = bgmm_model.covariances_\n",
    "\n",
    "        # Convert covariances to a NumPy array\n",
    "        covariances = np.array(covariances)\n",
    "\n",
    "        # Calculate the variances for each feature across components\n",
    "        variances = np.var(covariances, axis=0)\n",
    "\n",
    "        # Sort the variances in descending order\n",
    "        sorted_indices = np.argsort(variances)[::-1]\n",
    "        sorted_variances = variances[sorted_indices]\n",
    "\n",
    "        # Calculate the cumulative explained variance\n",
    "        cumulative_variance = np.cumsum(sorted_variances) / np.sum(sorted_variances)\n",
    "\n",
    "        # Determine the optimal number of features based on a threshold for cumulative variance explained\n",
    "        threshold = 0.95\n",
    "        num_features = np.sum(cumulative_variance < threshold) + 1\n",
    "        \n",
    "        # Save the selected features in the variable\n",
    "        selected_features = dataset[:, sorted_indices[:num_features]]\n",
    "\n",
    "        # Add the new dataset to data\n",
    "        data.append(selected_features)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relation(X, Y):\n",
    "\n",
    "\n",
    "    # Calculate Canonical Correlations by performaing Singular Value Decomposition (SVD)\n",
    "    U, D, V = svd(X.T @ Y)  \n",
    "    \n",
    "    # Get the rank of D (the number of non-zero canonical correlations)\n",
    "    r = np.linalg.matrix_rank(D)\n",
    "\n",
    "    # Select Significant Canonical Correlations\n",
    "    \n",
    "    # Determine the number of canonical correlations to keep\n",
    "    n = min(X.shape[1], Y.shape[1]) \n",
    "    \n",
    "    # Select r significant canonical correlatoins\n",
    "    canonical_correlations = D[:r]  \n",
    "\n",
    "    # Get canonical variates for predictor dataset\n",
    "    Wx = X @ U[:, :r]  \n",
    "    \n",
    "    # Get canonical variates for response dataset\n",
    "    Wy = Y @ V[:, :r]  \n",
    "   \n",
    "    # Compute distance matrix based on the canonical variates\n",
    "    num_samples = len(Wx)\n",
    "    \n",
    "    distances = np.zeros((num_samples, num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(i+1, num_samples): \n",
    "            # Compute the Euclidean distance between canonical variates\n",
    "            distance = np.sqrt((Wx[i]-Wx[j])**2 + (Wy[i] - Wy[j])**2)\n",
    "            distances[i, j] = distance\n",
    "            distances[j, i] = distance  \n",
    "    \n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "k1 = 18 # the neighbor of affinity matrix\n",
    "k2 = 42 # \n",
    "k3 = 2  # number of cluster\n",
    "c  = 3  # c = k3(c>2) or c = 3(c=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the affinity matrices in the same way as the MDICC paper did,\n",
    "# I would like to refer to the original paper:\n",
    "# Yang, Y., Tian, S., Qiu, Y., Zhao, P., & Zou, Q. (2022). \n",
    "# MDICC: Novel method for multi-omics data integration and cancer \n",
    "# subtype identification. Briefings in Bioinformatics, 23(3), bbac132.\n",
    "\n",
    "def kscale(matrix, k=7, dists=None, minval=0.004):\n",
    "    \"\"\" Returns the local scale based on the k-th nearest neighbour \"\"\"\n",
    "    r,c = matrix.shape\n",
    "    scale = np.zeros((r,c))\n",
    "    for i in range(1,(k+1)):\n",
    "        ix = (np.arange(len(matrix)), matrix.argsort(axis=0)[i])\n",
    "        d = matrix[ix][np.newaxis].T\n",
    "        dists = (d if dists is None else dists)\n",
    "        scale1 = dists.dot(dists.T)\n",
    "        \n",
    "        scale = scale1 + scale\n",
    "    scale = scale/k\n",
    "    return np.clip(scale, minval, np.inf)\n",
    "\n",
    "\n",
    "def affinity(matrix, k):\n",
    "    scale = kscale(matrix, k)\n",
    "    msq = matrix * matrix\n",
    "    scaled = -msq /(0.5*scale+0.5*matrix)\n",
    "    scaled[np.where(np.isnan(scaled))] = 0.0\n",
    "    a = np.exp(scaled)\n",
    "    a.flat[::matrix.shape[0]+1] = 0.0  # zero out the diagonal\n",
    "    return a\n",
    "\n",
    "\n",
    "def testaff(matrix,k):\n",
    "    k = int(k)\n",
    "    a = matrix\n",
    "    affi = affinity(a,k)\n",
    "    return affi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markp\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-53d6f0d34a13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmirna_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgene_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethy_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-02f8687b0b67>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(datasets)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Start KNN imputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_without_zeros\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Scale the data without the missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         )\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[1;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1869\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2037\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mnan_euclidean_distances\u001b[1;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[0mpresent_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmissing_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[0mpresent_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_X\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmissing_Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m     \u001b[0mpresent_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpresent_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m     \u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpresent_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;31m# avoid divide by zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = [mirna_data, gene_data, methy_data]\n",
    "data = get_data(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the affinity matrix for gene expression as predictor dataset and miRNA as response dataset\n",
    "d10 = calc_relation(data[1], data[0])\n",
    "A10 = testaff(d10, k1)\n",
    "pd.DataFrame(asarray(A10)).to_csv(\"A10_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for miRNA as predictor dataset and gene epxression as response dataset\n",
    "d01 = calc_relation(data[0], data[1])\n",
    "A01 = testaff(d01, k1)\n",
    "pd.DataFrame(asarray(A01)).to_csv(\"A01_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for gene expression as predictor dataset and methylation as response dataset\n",
    "d12 = calc_relation(data[1], data[2])\n",
    "A12 = testaff(d12, k1)\n",
    "pd.DataFrame(asarray(A12)).to_csv(\"A12_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for methylation as predictor dataset and gene epxression as response datas\n",
    "d21 = calc_relation(data[2], data[1])\n",
    "A21 = testaff(d21, k1)\n",
    "pd.DataFrame(asarray(A21)).to_csv(\"A21_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for methylation as predictor dataset and miRNA as response datas\n",
    "d20 = calc_relation(data[2], data[0])\n",
    "A20 = testaff(d20, k1)\n",
    "pd.DataFrame(asarray(A20)).to_csv(\"A20_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for miRNA as predictor dataset and methylation as response datas\n",
    "d02 = calc_relation(data[0], data[2])\n",
    "A02 = testaff(d02, k1)\n",
    "pd.DataFrame(asarray(A02)).to_csv(\"A02_BRCA.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
